{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69c83b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ADMIN\\anaconda3\\envs\\BJK\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load backtranslated dataset\n",
    "from datasets import load_from_disk\n",
    "squad_bt = load_from_disk(\"Backtranslated_squad_x2\")\n",
    "\n",
    "from datasets import load_dataset\n",
    "squad = load_dataset(\"squad\", split=\"train\")\n",
    "squad = squad.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"drill06_temp_distillation\")\n",
    "\n",
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"drill06_temp_distillation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9532ecb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7724c795a58f443c91eecd4d9dc5c6d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/140158 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db135fec4f6464cbb74c023e63d97e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=384,\n",
    "        truncation=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label it (0, 0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs\n",
    "tokenized_squad = squad_bt.map(preprocess_function, batched=True, remove_columns=squad_bt[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84a69809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce RTX 4060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_10432\\4231823804.py:37: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17520' max='17520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17520/17520 1:32:11, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.976700</td>\n",
       "      <td>1.100110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.769600</td>\n",
       "      <td>1.133806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ✅ Use GPU if available\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"There are {torch.cuda.device_count()} GPU(s) available.\")\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "    model.to(device)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU found, using CPU.\")\n",
    "\n",
    "# ✅ Training configuration (optimized for disk usage)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"drill12_temp&bt\",       # folder to save model\n",
    "    eval_strategy=\"epoch\",         # correct parameter name\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",               # save checkpoint only once per epoch\n",
    "    save_total_limit=1,                  # keep only the last checkpoint\n",
    "    load_best_model_at_end=True,\n",
    "    #gradient_accumulation_steps=2,      # optional if limited GPU memory\n",
    "    #fp16=True,                           # if you have CUDA (mixed precision)\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",                    # disable wandb or tensorboard logs\n",
    "    logging_dir=None,                    # avoid creating logging folders\n",
    ")\n",
    "\n",
    "# ✅ Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_squad[\"train\"],\n",
    "    eval_dataset=tokenized_squad[\"test\"],\n",
    "    tokenizer=tokenizer,                 # fixed from \"processing_class\"\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# ✅ Try to resume training if a checkpoint exists\n",
    "import os\n",
    "last_checkpoint = None\n",
    "if os.path.isdir(training_args.output_dir):\n",
    "    from transformers.trainer_utils import get_last_checkpoint\n",
    "    last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "\n",
    "if last_checkpoint:\n",
    "    print(f\"Resuming training from checkpoint: {last_checkpoint}\")\n",
    "    trainer.train(resume_from_checkpoint=last_checkpoint)\n",
    "else:\n",
    "    print(\"Starting training from scratch...\")\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0a8fd10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./drill12_temp&bt\\\\tokenizer_config.json',\n",
       " './drill12_temp&bt\\\\special_tokens_map.json',\n",
       " './drill12_temp&bt\\\\vocab.txt',\n",
       " './drill12_temp&bt\\\\added_tokens.json',\n",
       " './drill12_temp&bt\\\\tokenizer.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and tokenizer\n",
    "trainer.save_model(\"./drill12_temp&bt\")\n",
    "tokenizer.save_pretrained(\"./drill12_temp&bt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba253c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672a09ab9a82498eaddf42dd12e99afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_length = 384\n",
    "stride = 128\n",
    "\n",
    "\n",
    "def preprocess_validation_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    example_ids = []\n",
    "\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(examples[\"id\"][sample_idx])\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ]\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    return inputs\n",
    "\n",
    "validation_dataset = squad[\"test\"].map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=squad[\"test\"].column_names,\n",
    ")\n",
    "len(squad[\"test\"]), len(validation_dataset)\n",
    "from tqdm.auto import tqdm\n",
    "import collections\n",
    "import numpy as np\n",
    "import evaluate\n",
    "metric = evaluate.load(\"squad\")\n",
    "\n",
    "n_best = 20\n",
    "max_answer_length = 30\n",
    "\n",
    "def compute_metrics(start_logits, end_logits, features, examples):\n",
    "    example_to_features = collections.defaultdict(list)\n",
    "    for idx, feature in enumerate(features):\n",
    "        example_to_features[feature[\"example_id\"]].append(idx)\n",
    "\n",
    "    predicted_answers = []\n",
    "    for example in tqdm(examples):\n",
    "        example_id = example[\"id\"]\n",
    "        context = example[\"context\"]\n",
    "        answers = []\n",
    "\n",
    "        # Loop through all features associated with that example\n",
    "        for feature_index in example_to_features[example_id]:\n",
    "            start_logit = start_logits[feature_index]\n",
    "            end_logit = end_logits[feature_index]\n",
    "            offsets = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # Skip answers that are not fully in the context\n",
    "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                        continue\n",
    "                    # Skip answers with a length that is either < 0 or > max_answer_length\n",
    "                    if (\n",
    "                        end_index < start_index\n",
    "                        or end_index - start_index + 1 > max_answer_length\n",
    "                    ):\n",
    "                        continue\n",
    "\n",
    "                    answer = {\n",
    "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "\n",
    "        # Select the answer with the best score\n",
    "        if len(answers) > 0:\n",
    "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "            predicted_answers.append(\n",
    "                {\"id\": example_id, \"prediction_text\": best_answer[\"text\"]}\n",
    "            )\n",
    "        else:\n",
    "            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n",
    "\n",
    "    theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples]\n",
    "    return metric.compute(predictions=predicted_answers, references=theoretical_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f635d2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25bca9425d39498caa47d37f288d753f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'exact_match': 64.56050228310502, 'f1': 78.02282616087746}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, _, _ = trainer.predict(validation_dataset)\n",
    "start_logits, end_logits = predictions\n",
    "compute_metrics(start_logits, end_logits, validation_dataset, squad[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa5f270",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the weight of Jo?\n",
      "600 kg\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the weight of Jo?\"\n",
    "context=\"Prince weight 800 kg and Jo weight 600 kg.\"\n",
    "print(question)\n",
    "from transformers import pipeline\n",
    "question_answerer = pipeline(\"question-answering\", \n",
    "                             model=\"./drill12_temp&bt\",\n",
    "                            tokenizer=\"./drill12_temp&bt\",\n",
    "                            fp16=True)\n",
    "\n",
    "result = question_answerer(question=question, context=context)\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475a7182",
   "metadata": {},
   "source": [
    "Sir Isaac Newton, a 17th-century English physicist and mathematician, introduced the three laws of motion in his famous work Philosophiæ Naturalis Principia Mathematica, published in 1687. These laws provide a comprehensive description of how objects behave when forces act upon them. Together, they form the foundation of classical mechanics and continue to be used in physics, engineering, and aerospace science.Newton’s First Law, also known as the Law of Inertia, states that an object will remain at rest or continue moving at a constant velocity in a straight line unless acted upon by a net external force. This explains why passengers in a car lung forward when the vehicle suddenly stops—their bodies were moving at the same speed as the car and continue moving forward due to inertia.Newton’s Second Law describes how forces affect motion. It states that the acceleration of an object is directly proportional to the net force acting on it and inversely proportional to its mass. This is expressed mathematically as F = m × a. The larger the force applied to an object, the greater its acceleration; however, heavier objects require more force to achieve the same acceleration. For example, pushing an empty shopping cart is easier than pushing a full one because it has less mass.Newton’s Third Law states that for every action, there is an equal and opposite reaction. This means that forces always occur in pairs. When a person walks, their foot pushes backward on the ground, and the ground pushes forward on the person with equal strength, allowing them to move. This is also why rockets can move in space: they push exhaust gases backward at high speed, and the reaction force pushes the rocket forward.These laws apply to countless real-world situations. Engineers use Newton’s laws to design vehicles, calculate load distributions in buildings, and analyze motion in machinery. Astronomers use them to understand planetary motion and gravitational interactions. Even modern technologies like drones and robotic arms rely on Newton’s principles for stability and control.Although modern physics, especially relativity and quantum mechanics, extends beyond Newton’s framework, the laws of motion remain accurate for most everyday situations involving moderate speeds, large objects, and non-extreme conditions. They are still the first tools taught to students learning physics and mechanics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19d520b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are Newton’s laws still accurate in modern physics?\n",
      "they form the foundation of classical mechanics\n"
     ]
    }
   ],
   "source": [
    "question = \"Are Newton’s laws still accurate in modern physics?\"\n",
    "context=\"Sir Isaac Newton, a 17th-century English physicist and mathematician, introduced the three laws of motion in his famous work Philosophiæ Naturalis Principia Mathematica, published in 1687. These laws provide a comprehensive description of how objects behave when forces act upon them. Together, they form the foundation of classical mechanics and continue to be used in physics, engineering, and aerospace science.Newton’s First Law, also known as the Law of Inertia, states that an object will remain at rest or continue moving at a constant velocity in a straight line unless acted upon by a net external force. This explains why passengers in a car lung forward when the vehicle suddenly stops—their bodies were moving at the same speed as the car and continue moving forward due to inertia.Newton’s Second Law describes how forces affect motion. It states that the acceleration of an object is directly proportional to the net force acting on it and inversely proportional to its mass. This is expressed mathematically as F = m × a. The larger the force applied to an object, the greater its acceleration; however, heavier objects require more force to achieve the same acceleration. For example, pushing an empty shopping cart is easier than pushing a full one because it has less mass.Newton’s Third Law states that for every action, there is an equal and opposite reaction. This means that forces always occur in pairs. When a person walks, their foot pushes backward on the ground, and the ground pushes forward on the person with equal strength, allowing them to move. This is also why rockets can move in space: they push exhaust gases backward at high speed, and the reaction force pushes the rocket forward.These laws apply to countless real-world situations. Engineers use Newton’s laws to design vehicles, calculate load distributions in buildings, and analyze motion in machinery. Astronomers use them to understand planetary motion and gravitational interactions. Even modern technologies like drones and robotic arms rely on Newton’s principles for stability and control.Although modern physics, especially relativity and quantum mechanics, extends beyond Newton’s framework, the laws of motion remain accurate for most everyday situations involving moderate speeds, large objects, and non-extreme conditions. They are still the first tools taught to students learning physics and mechanics.\"\n",
    "print(question)\n",
    "from transformers import pipeline\n",
    "question_answerer = pipeline(\"question-answering\", \n",
    "                             model=\"./drill12_temp&bt\",\n",
    "                            tokenizer=\"./drill12_temp&bt\",\n",
    "                            fp16=True)\n",
    "\n",
    "result = question_answerer(question=question, context=context)\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dee129",
   "metadata": {},
   "source": [
    "The story of the Three Little Pigs begins with three siblings who decide to build their own houses. The first little pig, wanting to finish quickly and spend the rest of the day playing, builds a simple house made of straw. Although it is easy to construct, the house is weak and offers little protection.The second little pig puts in a bit more effort and builds his house from sticks. The stick house is stronger than the straw one, but it is still not very sturdy. He finishes his work faster than expected and joins the first pig to relax.The third little pig, however, works hard and carefully builds a strong house from bricks. His siblings laugh at him for taking so long, but he knows that a solid house will keep him safe.One day, a big bad wolf comes along. Hungry and determined to catch the pigs, he approaches the first pig’s straw house. The wolf knocks on the door and demands to be let in, but the pig refuses. Angry, the wolf takes a huge breath and blows the straw house down with ease. The first pig runs away to the stick house.The wolf follows and arrives at the second pig’s stick house. He again demands to be let in, and when the pigs refuse, he huffs and puffs and blows down the stick house as well. Both pigs flee to their brother’s brick house.Finally, the wolf comes to the brick house. He tries to blow it down, but no matter how hard he huffs and puffs, the brick house stands strong. Growing frustrated, the wolf climbs onto the roof and attempts to enter through the chimney. However, the clever third pig has already prepared a pot of boiling water in the fireplace.When the wolf drops down the chimney, he falls straight into the boiling water and leaps out in pain, fleeing into the forest, never to bother the pigs again. The three little pigs learn that hard work and careful planning pay off, and they live safely in the brick house from that day forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7d2098d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do quantum particles behave like everyday objects?\n",
      "differently\n"
     ]
    }
   ],
   "source": [
    "question = \"Do quantum particles behave like everyday objects?\"\n",
    "context=\"In quantum physics, very small particles like electrons and photons behave differently from everyday objects. These particles can act as both waves and particles, a concept called wave–particle duality. Their exact position cannot be known with complete certainty; instead, scientists describe their location using probability. Quantum particles can also be entangled, meaning the state of one particle is instantly connected to the state of another, even if they are far apart.\"\n",
    "print(question)\n",
    "from transformers import pipeline\n",
    "question_answerer = pipeline(\"question-answering\", \n",
    "                             model=\"./drill12_temp&bt\",\n",
    "                            tokenizer=\"./drill12_temp&bt\",\n",
    "                            fp16=True)\n",
    "\n",
    "result = question_answerer(question=question, context=context)\n",
    "print(result['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BJK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
