{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a2655ef1",
      "metadata": {
        "id": "a2655ef1",
        "outputId": "2ed74b49-5671-49a9-f7d1-a39878c6f08c"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "squad = load_dataset(\"squad\", split=\"train\")\n",
        "squad = squad.train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
        "\n",
        "from transformers import DefaultDataCollator\n",
        "\n",
        "data_collator = DefaultDataCollator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "2f8421eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "280224d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import load_from_disk, load_dataset, concatenate_datasets, Dataset\n",
        "\n",
        "# 1️⃣ Load existing dataset\n",
        "dataset_fr = load_from_disk(\"squad_backtranslated/\")\n",
        "\n",
        "# 2️⃣ Load CSV\n",
        "# This returns a DatasetDict, usually with a 'train' split\n",
        "dataset_de = load_dataset('csv', data_files=\"augmented_squad.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "278bf33f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "358075d1e6b14444a0a967bb4af85452",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/70079 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before:\n",
            "{'answer_start': array([316]), 'text': array(['US$10,000'], dtype=object)}\n",
            "\n",
            "After:\n",
            "{'answer_start': [316], 'text': ['US$10,000']}\n",
            "\n",
            "French (target):\n",
            "{'text': ['US$10,000'], 'answer_start': [316]}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61ce08fb884d49b1ab764a0717ee0d71",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Casting the dataset:   0%|          | 0/70079 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Success! Combined dataset size: 140158\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from datasets import Dataset\n",
        "\n",
        "def parse_answers_from_string(example):\n",
        "    \"\"\"Parse string representation of dict with numpy arrays\"\"\"\n",
        "    answers_str = example['answers']\n",
        "    \n",
        "    # Extract text using regex\n",
        "    text_match = re.search(r\"'text': array\\(\\['(.+?)'\\]\", answers_str)\n",
        "    text_value = text_match.group(1) if text_match else \"\"\n",
        "    \n",
        "    # Extract answer_start using regex\n",
        "    start_match = re.search(r\"'answer_start': array\\(\\[(\\d+)\\]\", answers_str)\n",
        "    start_value = int(start_match.group(1)) if start_match else 0\n",
        "    \n",
        "    # Convert to HF format (lists)\n",
        "    example['answers'] = {\n",
        "        'text': [text_value],\n",
        "        'answer_start': [start_value]\n",
        "    }\n",
        "    \n",
        "    return example\n",
        "\n",
        "# Apply the conversion\n",
        "dataset_de_converted = dataset_de['train'].map(parse_answers_from_string)\n",
        "\n",
        "# Verify\n",
        "print(\"Before:\")\n",
        "print(dataset_de['train']['answers'][1])\n",
        "print(\"\\nAfter:\")\n",
        "print(dataset_de_converted['answers'][1])\n",
        "print(\"\\nFrench (target):\")\n",
        "print(dataset_fr['train']['answers'][1])\n",
        "\n",
        "# Cast to match exact features\n",
        "dataset_de_converted = dataset_de_converted.cast(dataset_fr['train'].features)\n",
        "\n",
        "# Concatenate\n",
        "from datasets import concatenate_datasets\n",
        "combined_dataset = concatenate_datasets([dataset_fr['train'], dataset_de_converted])\n",
        "print(f\"\\nSuccess! Combined dataset size: {len(combined_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "5f7c7f06",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "    num_rows: 140158\n",
              "})"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "combined_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "3a978b8b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import copy\n",
        "augmented_squad = copy.deepcopy(squad)\n",
        "augmented_squad['train'] = combined_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "5b89ae22",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 140158\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 17520\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "augmented_squad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "8e951caa",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the nearest port to Saint Helena?\n",
            "Which port is closest to St. Helena?\n",
            "What is the nearest port to St. Helena?\n"
          ]
        }
      ],
      "source": [
        "print(squad['train']['question'][5])\n",
        "print(augmented_squad['train']['question'][5])\n",
        "print(augmented_squad['train']['question'][70084])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "id": "6045c440",
      "metadata": {
        "id": "6045c440"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        max_length=384,\n",
        "        truncation=\"longest_first\",\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    answers = examples[\"answers\"]\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        answer = answers[i]\n",
        "        start_char = answer[\"answer_start\"][0]\n",
        "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # Find the start and end of the context\n",
        "        idx = 0\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx += 1\n",
        "        context_start = idx\n",
        "        while sequence_ids[idx] == 1:\n",
        "            idx += 1\n",
        "        context_end = idx - 1\n",
        "\n",
        "        # If the answer is not fully inside the context, label it (0, 0)\n",
        "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Otherwise it's the start and end token positions\n",
        "            idx = context_start\n",
        "            while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "            start_positions.append(idx - 1)\n",
        "\n",
        "            idx = context_end\n",
        "            while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            end_positions.append(idx + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "id": "fa710405",
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
        "\n",
        "from transformers import DefaultDataCollator\n",
        "\n",
        "data_collator = DefaultDataCollator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "id": "7b4d33a6",
      "metadata": {
        "id": "7b4d33a6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f7e3bb82641476aad5499c8e8a9bb7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/140158 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ebdd3bf1b47b4e5f828274b48f3dd403",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/17520 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_squad = augmented_squad.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=augmented_squad[\"train\"].column_names,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "id": "fa2e6138",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Jettanat\\anaconda3\\envs\\fuckingneuralnetwork\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "Trainable parameters: 70\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"./drill04_qa_model\")\n",
        "\n",
        "# Freeze first 2 transformer layers\n",
        "for layer in model.distilbert.transformer.layer[:2]:\n",
        "    for param in layer.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "# Check which parameters are trainable\n",
        "trainable_params = [n for n, p in model.named_parameters() if p.requires_grad]\n",
        "print(f\"Trainable parameters: {len(trainable_params)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "id": "ec62030e",
      "metadata": {
        "id": "ec62030e",
        "outputId": "9bbffb4c-61f3-4846-e8ea-ac6627e09030"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: NVIDIA GeForce RTX 3050 Laptop GPU\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Jettanat\\AppData\\Local\\Temp\\ipykernel_24640\\999138565.py:33: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='17520' max='17520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [17520/17520 2:50:54, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.847400</td>\n",
              "      <td>1.125801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.773400</td>\n",
              "      <td>1.141264</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=17520, training_loss=0.8348809875854074, metrics={'train_runtime': 10254.8273, 'train_samples_per_second': 27.335, 'train_steps_per_second': 1.708, 'total_flos': 2.7468115791427584e+16, 'train_loss': 0.8348809875854074, 'epoch': 2.0})"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ✅ Use GPU if available\n",
        "import torch\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"There are {torch.cuda.device_count()} GPU(s) available.\")\n",
        "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
        "    model.to(device)\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"No GPU found, using CPU.\")\n",
        "\n",
        "# ✅ Training configuration (optimized for disk usage)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"drill04+DE_Backtranslated\",       # folder to save model\n",
        "    eval_strategy=\"epoch\",         # correct parameter name\n",
        "    learning_rate=5e-6,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"epoch\",               # save checkpoint only once per epoch\n",
        "    save_total_limit=1,                  # keep only the last checkpoint\n",
        "    load_best_model_at_end=True,         # optional, keeps best checkpoint\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",                    # disable wandb or tensorboard logs\n",
        "    logging_dir=None,                    # avoid creating logging folders\n",
        "    #fp16=True\n",
        ")\n",
        "\n",
        "# ✅ Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_squad[\"train\"],\n",
        "    eval_dataset=tokenized_squad[\"test\"],\n",
        "    tokenizer=tokenizer,                 # fixed from \"processing_class\"\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "id": "e6f9d3f0",
      "metadata": {
        "id": "e6f9d3f0",
        "outputId": "6d5e86e6-5e1d-4d94-eaf1-e9c919a6184e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./drill04+DE+FR_Backtranslated\\\\tokenizer_config.json',\n",
              " './drill04+DE+FR_Backtranslated\\\\special_tokens_map.json',\n",
              " './drill04+DE+FR_Backtranslated\\\\vocab.txt',\n",
              " './drill04+DE+FR_Backtranslated\\\\added_tokens.json',\n",
              " './drill04+DE+FR_Backtranslated\\\\tokenizer.json')"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the model and tokenizer\n",
        "trainer.save_model(\"./drill04+DE+FR_Backtranslated\")\n",
        "tokenizer.save_pretrained(\"./drill04+DE+FR_Backtranslated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "id": "551c8bf0",
      "metadata": {
        "id": "551c8bf0",
        "outputId": "b40ff1c3-c7b5-4b97-de3d-a4a5b91288fa"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f1d2979ae25403db68220d676ea69c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/17520 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(17520, 17688)"
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_length = 384\n",
        "stride = 128\n",
        "\n",
        "\n",
        "def preprocess_validation_examples(examples):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        max_length=max_length,\n",
        "        truncation=\"only_second\",\n",
        "        stride=stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
        "    example_ids = []\n",
        "\n",
        "    for i in range(len(inputs[\"input_ids\"])):\n",
        "        sample_idx = sample_map[i]\n",
        "        example_ids.append(examples[\"id\"][sample_idx])\n",
        "\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "        offset = inputs[\"offset_mapping\"][i]\n",
        "        inputs[\"offset_mapping\"][i] = [\n",
        "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
        "        ]\n",
        "\n",
        "    inputs[\"example_id\"] = example_ids\n",
        "    return inputs\n",
        "\n",
        "validation_dataset = squad[\"test\"].map(\n",
        "    preprocess_validation_examples,\n",
        "    batched=True,\n",
        "    remove_columns=squad[\"test\"].column_names,\n",
        ")\n",
        "len(squad[\"test\"]), len(validation_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "id": "9b91bec1",
      "metadata": {
        "id": "9b91bec1"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "import collections\n",
        "import numpy as np\n",
        "import evaluate\n",
        "metric = evaluate.load(\"squad\")\n",
        "\n",
        "n_best = 20\n",
        "max_answer_length = 30\n",
        "\n",
        "def compute_metrics(start_logits, end_logits, features, examples):\n",
        "    example_to_features = collections.defaultdict(list)\n",
        "    for idx, feature in enumerate(features):\n",
        "        example_to_features[feature[\"example_id\"]].append(idx)\n",
        "\n",
        "    predicted_answers = []\n",
        "    for example in tqdm(examples):\n",
        "        example_id = example[\"id\"]\n",
        "        context = example[\"context\"]\n",
        "        answers = []\n",
        "\n",
        "        # Loop through all features associated with that example\n",
        "        for feature_index in example_to_features[example_id]:\n",
        "            start_logit = start_logits[feature_index]\n",
        "            end_logit = end_logits[feature_index]\n",
        "            offsets = features[feature_index][\"offset_mapping\"]\n",
        "\n",
        "            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
        "            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
        "            for start_index in start_indexes:\n",
        "                for end_index in end_indexes:\n",
        "                    # Skip answers that are not fully in the context\n",
        "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
        "                        continue\n",
        "                    # Skip answers with a length that is either < 0 or > max_answer_length\n",
        "                    if (\n",
        "                        end_index < start_index\n",
        "                        or end_index - start_index + 1 > max_answer_length\n",
        "                    ):\n",
        "                        continue\n",
        "\n",
        "                    answer = {\n",
        "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
        "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
        "                    }\n",
        "                    answers.append(answer)\n",
        "\n",
        "        # Select the answer with the best score\n",
        "        if len(answers) > 0:\n",
        "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
        "            predicted_answers.append(\n",
        "                {\"id\": example_id, \"prediction_text\": best_answer[\"text\"]}\n",
        "            )\n",
        "        else:\n",
        "            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n",
        "\n",
        "    theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples]\n",
        "    return metric.compute(predictions=predicted_answers, references=theoretical_answers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "id": "748358f6",
      "metadata": {
        "id": "748358f6",
        "outputId": "c717aa47-93f3-4706-a1f6-798ceff48909"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e0b2798eb7a4787a8f6aaed039dd474",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/17520 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'exact_match': 64.46917808219177, 'f1': 78.29335437423069}"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions, _, _ = trainer.predict(validation_dataset)\n",
        "start_logits, end_logits = predictions\n",
        "compute_metrics(start_logits, end_logits, validation_dataset, squad[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "id": "ac1dddd9",
      "metadata": {
        "id": "ac1dddd9",
        "outputId": "6ead3be7-cac1-494d-a6b8-1078a3841b0e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Which is blue's car price\n",
            "$20,000 and the red car costs $25,000\n"
          ]
        }
      ],
      "source": [
        "question = \"Which is blue's car price\"\n",
        "context=\"The blue car costs $20,000 and the red car costs $25,000.\"\n",
        "print(question)\n",
        "from transformers import pipeline\n",
        "question_answerer = pipeline(\"question-answering\",\n",
        "                             model=\"./drill04_qa_model\",\n",
        "                            tokenizer=\"./drill04_qa_model\",\n",
        "                            fp16=True)\n",
        "\n",
        "result = question_answerer(question=question, context=context)\n",
        "print(result['answer'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "fuckingneuralnetwork",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
